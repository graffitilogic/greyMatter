using System;
using System.Linq;
using System.Threading.Tasks;
using GreyMatter.Core;

namespace GreyMatter
{
    /// <summary>
    /// Test sparse concept encoding for balanced efficiency and meaningful learning
    /// Demonstrates biologically-inspired approach to massive scale vocabulary
    /// </summary>
    public class SparseEncodingTest
    {
        public static async Task RunSparseEncodingTest()
        {
            Console.WriteLine("üß† **SPARSE CONCEPT ENCODING TEST**");
            Console.WriteLine("=====================================");
            Console.WriteLine("Testing biologically-inspired efficient vocabulary encoding");
            Console.WriteLine("Human cortex: ~2% neuron activation, rich semantic relationships");
            Console.WriteLine();

            var encoder = new SparseConceptEncoder(patternSize: 2048, sparsity: 0.02);

            // Test 1: Basic word encoding
            Console.WriteLine("üìù **TEST 1: Basic Word Encoding**");
            var apple1 = encoder.EncodeWord("apple", "red fruit tree");
            var apple2 = encoder.EncodeWord("apple", "red fruit tree"); // Same context
            var apple3 = encoder.EncodeWord("apple", "computer technology"); // Different context
            
            Console.WriteLine($"   Apple (fruit context): {apple1.ActiveBits.Length} active bits (sparsity: {(double)apple1.ActiveBits.Length / 2048:P1})");
            Console.WriteLine($"   Apple (fruit context repeat): {apple2.ActiveBits.Length} active bits");
            Console.WriteLine($"   Apple (tech context): {apple3.ActiveBits.Length} active bits");
            
            var similarity12 = encoder.CalculateSimilarity(apple1, apple2);
            var similarity13 = encoder.CalculateSimilarity(apple1, apple3);
            
            Console.WriteLine($"   Similarity (same context): {similarity12:P1}");
            Console.WriteLine($"   Similarity (different context): {similarity13:P1}");
            Console.WriteLine();

            // Test 2: Semantic relationships
            Console.WriteLine("üîó **TEST 2: Semantic Relationships**");
            var cat = encoder.EncodeWord("cat", "animal pet furry");
            var dog = encoder.EncodeWord("dog", "animal pet loyal");
            var car = encoder.EncodeWord("car", "vehicle transportation");
            
            var catDogSimilarity = encoder.CalculateSimilarity(cat, dog);
            var catCarSimilarity = encoder.CalculateSimilarity(cat, car);
            
            Console.WriteLine($"   Cat-Dog similarity (both animals): {catDogSimilarity:P1}");
            Console.WriteLine($"   Cat-Car similarity (unrelated): {catCarSimilarity:P1}");
            Console.WriteLine();

            // Test 3: Scalability demonstration
            Console.WriteLine("üìà **TEST 3: Scalability Test**");
            var words = new[]
            {
                ("running", "fast movement exercise"),
                ("walking", "slow movement exercise"),
                ("swimming", "water movement exercise"),
                ("reading", "books learning education"),
                ("writing", "text creation communication"),
                ("thinking", "mental cognitive process"),
                ("learning", "education knowledge growth"),
                ("teaching", "education knowledge sharing"),
                ("cooking", "food preparation kitchen"),
                ("eating", "food consumption nutrition")
            };

            Console.WriteLine($"   Encoding {words.Length} words with rich contextual information...");
            
            foreach (var (word, context) in words)
            {
                var pattern = encoder.EncodeWord(word, context);
                Console.WriteLine($"   {word}: {pattern.ActiveBits.Length} bits ({pattern.ActivationStrength:F1} strength)");
            }
            
            var stats = (ConceptCount: encoder.ConceptCount, AvgSparsity: encoder.AverageSparsity);
            Console.WriteLine($"\n   üìä Total concepts: {stats.ConceptCount}");
            Console.WriteLine($"   üìä Average sparsity: {stats.AvgSparsity:P1}");
            Console.WriteLine();

            // Test 4: Memory efficiency calculation
            Console.WriteLine("üíæ **TEST 4: Memory Efficiency Analysis**");
            
            // Traditional approach (hypothetical full neuron allocation)
            var traditionalNeurons = words.Length * 600; // 600 neurons per word (old approach)
            var traditionalMemory = traditionalNeurons * 64; // 64 bytes per neuron (rough estimate)
            
            // Sparse approach
            var sparseActiveBits = words.Length * (int)(2048 * 0.02); // ~41 active bits per word
            var sparseMemory = sparseActiveBits * 4; // 4 bytes per bit index
            
            Console.WriteLine($"   Traditional approach: {traditionalNeurons:N0} neurons, ~{traditionalMemory / 1024:N0} KB");
            Console.WriteLine($"   Sparse approach: {sparseActiveBits:N0} active bits, ~{sparseMemory / 1024:N0} KB");
            Console.WriteLine($"   Memory reduction: {(1.0 - (double)sparseMemory / traditionalMemory):P1}");
            Console.WriteLine();

            // Test 5: Contextual variations
            Console.WriteLine("üé≠ **TEST 5: Contextual Variations**");
            var bankFinancial = encoder.EncodeWord("bank", "money financial institution");
            var bankRiver = encoder.EncodeWord("bank", "river water shore");
            var bankMemory = encoder.EncodeWord("bank", "computer memory storage");
            
            var bankSim12 = encoder.CalculateSimilarity(bankFinancial, bankRiver);
            var bankSim13 = encoder.CalculateSimilarity(bankFinancial, bankMemory);
            var bankSim23 = encoder.CalculateSimilarity(bankRiver, bankMemory);
            
            Console.WriteLine($"   Bank (financial) vs Bank (river): {bankSim12:P1} similarity");
            Console.WriteLine($"   Bank (financial) vs Bank (memory): {bankSim13:P1} similarity");
            Console.WriteLine($"   Bank (river) vs Bank (memory): {bankSim23:P1} similarity");
            Console.WriteLine();

            Console.WriteLine("‚úÖ **SPARSE ENCODING ADVANTAGES:**");
            Console.WriteLine("   üéØ Massive scalability (2% sparsity like human cortex)");
            Console.WriteLine("   üß† Rich semantic relationships through multi-column encoding");
            Console.WriteLine("   üîÑ Multiple encodings for same concept (biological redundancy)");
            Console.WriteLine("   üìä Context-sensitive representations");
            Console.WriteLine("   üíæ Exponential memory efficiency gains");
            Console.WriteLine("   üöÄ Ready for million+ word vocabularies");
            Console.WriteLine();
            
            Console.WriteLine("üî¨ **BIOLOGICAL INSPIRATION:**");
            Console.WriteLine("   üß¨ Cortical columns: Specialized for phonetic, semantic, syntactic features");
            Console.WriteLine("   ‚ö° Sparse activation: Only 2% of neurons active (like human cortex)");
            Console.WriteLine("   üîó Distributed representation: Rich associations across multiple patterns");
            Console.WriteLine("   üß† Neural plasticity: Slight variations each time (biological noise)");
        }
    }
}
